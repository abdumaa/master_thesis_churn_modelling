{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39164bit1b7085399b144131b3c6aab0c8fc3c91",
   "display_name": "Python 3.9.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "sys.path.append(os.path.dirname(SCRIPT_DIR[:-11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn_modelling.modelling.lgbm import LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_modelling = LGBM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length of training set: 80000\nLength of validation set: 10000\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = gbt_modelling.create_train_val()\n",
    "print(f\"Length of training set: {len(df_train)}\\nLength of validation set: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    79172\n1     8280\nName: churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train_sampled = gbt_modelling.create_sampling(\n",
    "    df_to_sample=df_train,\n",
    "    sampling=\"up\",\n",
    "    frac=10,\n",
    ")\n",
    "print(df_train_sampled[\"churn\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------ COMPUTE CORRELATION MATRIX\n",
      "------------------ START ITERATING THROUGH FEATURE SET\n",
      "------------------ ITERATION STEP 1\n",
      "n_requests_1 selected with MRMR-Score: 14.8\n",
      "------------------ ITERATION STEP 2\n",
      "diff_avg_vjnbe_requests_3 selected with MRMR-Score: 496.50286621980416\n",
      "------------------ ITERATION STEP 3\n",
      "diff_n_requests_3 selected with MRMR-Score: 313.3010359487711\n",
      "------------------ ITERATION STEP 4\n",
      "diff_avg_vjnbe_requests_2 selected with MRMR-Score: 273.01295548488093\n",
      "------------------ ITERATION STEP 5\n",
      "diff_n_requests_1 selected with MRMR-Score: 300.7288947922638\n",
      "------------------ ITERATION STEP 6\n",
      "other_hsntsn_requests_3 selected with MRMR-Score: 328.63438936914616\n",
      "------------------ ITERATION STEP 7\n",
      "diff_n_requests_2 selected with MRMR-Score: 430.06650075957225\n",
      "------------------ ITERATION STEP 8\n",
      "other_hsntsn_requests_2 selected with MRMR-Score: 451.5899446688075\n",
      "------------------ ITERATION STEP 9\n",
      "n_requests_3 selected with MRMR-Score: 496.547588216469\n",
      "------------------ ITERATION STEP 10\n",
      "n_requests_2 selected with MRMR-Score: 675.990992949613\n",
      "------------------ ITERATION STEP 11\n",
      "diff_avg_vjnbe_requests_1 selected with MRMR-Score: 512.1437212693965\n",
      "------------------ ITERATION STEP 12\n",
      "other_hsntsn_requests_1 selected with MRMR-Score: 900.406444858926\n",
      "------------------ END ITERATING THROUGH FEATURE SET\n",
      "Best set of features: ['n_requests_1', 'diff_avg_vjnbe_requests_3', 'diff_n_requests_3', 'other_hsntsn_requests_3', 'n_accident', 'sum_accident_cost', 'vehicle_age', 'diff_car_holder', 'contract_age_months', 'age_contract_holder', 'age_youngest_driver', 'years_driving_license', 'churn']\n"
     ]
    }
   ],
   "source": [
    "best_feats = gbt_modelling.get_best_quot_features(\n",
    "    df_to_dimreduce=df_train_sampled,\n",
    "    cv=5,\n",
    "    return_fix_features=True,\n",
    "    return_target=True\n",
    ")\n",
    "print(f\"Best set of features: {best_feats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "hp_fix_dict = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"max_depth\": -1,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"importance_type\": \"split\",\n",
    "}\n",
    "hp_tune_dict = {\n",
    "    \"num_leaves\": sp_randint(6, 50),\n",
    "    \"min_child_weight\": [1e-5, 1e-2, 1e-1, 1, 1e1, 1e4],\n",
    "    \"min_child_samples\": sp_randint(100, 500),\n",
    "    \"subsample\": sp_uniform(loc=0.4, scale=0.6),\n",
    "    \"colsample_bytree\": sp_uniform(loc=0.6, scale=0.4),\n",
    "    \"reg_alpha\": [0, 1, 5, 10, 100],\n",
    "    \"reg_lambda\": [0, 1, 5, 10, 100],\n",
    "}\n",
    "hp_eval_dict = {\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"callbacks\": [lgb.log_evaluation(100), lgb.early_stopping(30)],\n",
    "}\n",
    "rscv_params = {\n",
    "    \"n_iter\": 100,\n",
    "    \"n_jobs\": -1,\n",
    "    \"cv\": 3,\n",
    "    \"verbose\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "..1: Small preprocessing\n",
      "Memory usage decreased to  1.67 Mb (80.8% reduction)\n",
      "Memory usage decreased to  0.25 Mb (76.8% reduction)\n",
      "..2: Start CV-HP-Tuning\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0802366\n",
      "[200]\tvalid_0's binary_logloss: 0.0771463\n",
      "[300]\tvalid_0's binary_logloss: 0.0762611\n",
      "[400]\tvalid_0's binary_logloss: 0.075946\n",
      "[500]\tvalid_0's binary_logloss: 0.0758279\n",
      "[600]\tvalid_0's binary_logloss: 0.0757284\n",
      "[700]\tvalid_0's binary_logloss: 0.0756335\n",
      "[800]\tvalid_0's binary_logloss: 0.075535\n",
      "[900]\tvalid_0's binary_logloss: 0.0754311\n",
      "[1000]\tvalid_0's binary_logloss: 0.0753327\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0753327\n",
      "..3: Finished CV-HP-Tuning\n",
      "Best score reached: 0.9498124501042943 with params: {'colsample_bytree': 0.8891192644013817, 'min_child_samples': 261, 'min_child_weight': 1e-05, 'num_leaves': 47, 'reg_alpha': 1, 'reg_lambda': 10, 'subsample': 0.6217798214195256} \n",
      "..4: Save best model\n"
     ]
    }
   ],
   "source": [
    "gbt_fit = gbt_modelling.fit_lgbm(\n",
    "    df_train=df_train_sampled,\n",
    "    df_val=df_val,\n",
    "    hp_fix_dict=hp_fix_dict,\n",
    "    hp_tune_dict=hp_tune_dict,\n",
    "    hp_eval_dict=hp_eval_dict,\n",
    "    rscv_params=rscv_params,\n",
    "    feature_set=best_feats,\n",
    "    cl_alpha=None,\n",
    "    cl_gamma=None,\n",
    "    save_model=True,\n",
    "    cache_model_name=\"lgbm_fit_gbt_up1_best_quot_aNone_gNone\",\n",
    "    path_to_folder=SCRIPT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memory usage decreased to  0.25 Mb (75.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "preds, preds_proba = gbt_modelling.predict(\n",
    "    gbt_modelling.df_oos,\n",
    "    predict_from_cached_fit=False,\n",
    "    fit=gbt_fit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy_OOS: 0.985 \nPrecision_OOS: 0.3089 \nRecall_OOS: 0.3689 \nF1_Score_OOS: 0.3363 \nAUROC_OOS: 0.8796 \nAUPRC_OOS: 0.3298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "print('Accuracy_OOS:', round(accuracy_score(gbt_modelling.df_oos[\"churn\"], preds), 4),\n",
    "'\\nPrecision_OOS:', round(precision_score(gbt_modelling.df_oos[\"churn\"], preds), 4),\n",
    "'\\nRecall_OOS:', round(recall_score(gbt_modelling.df_oos[\"churn\"], preds), 4),\n",
    "'\\nF1_Score_OOS:', round(f1_score(gbt_modelling.df_oos[\"churn\"], preds), 4),\n",
    "'\\nAUROC_OOS:', round(roc_auc_score(gbt_modelling.df_oos[\"churn\"], preds_proba), 4),\n",
    "'\\nAUPRC_OOS:', round(average_precision_score(gbt_modelling.df_oos[\"churn\"], preds_proba), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "hp_fix_dict = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"max_depth\": -1,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"importance_type\": \"split\",\n",
    "}\n",
    "hp_tune_dict = {\n",
    "    \"num_leaves\": sp_randint(6, 50),\n",
    "    \"min_child_weight\": [1e-5, 1e-2, 1e-1, 1, 1e1, 1e4],\n",
    "    \"min_child_samples\": sp_randint(100, 500),\n",
    "    \"subsample\": sp_uniform(loc=0.4, scale=0.6),\n",
    "    \"colsample_bytree\": sp_uniform(loc=0.6, scale=0.4),\n",
    "    \"reg_alpha\": [0, 1, 5, 10, 100],\n",
    "    \"reg_lambda\": [0, 1, 5, 10, 100],\n",
    "}\n",
    "hp_eval_dict = {\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"callbacks\": [lgb.log_evaluation(100), lgb.early_stopping(30)],\n",
    "}\n",
    "rscv_params = {\n",
    "    \"n_iter\": 100,\n",
    "    \"n_jobs\": -1,\n",
    "    \"cv\": 3,\n",
    "    \"verbose\": 100,\n",
    "}\n",
    "hp_struct_dict = {\n",
    "    'sampling': {\n",
    "        'down1': 0.1,\n",
    "        'down2': 0.5,\n",
    "    },\n",
    "    'dr_method': ['no_quot', 'best_quot'],\n",
    "    'cl_alpha': [None, 0.6],\n",
    "    'cl_gamma': [None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------ COMPUTE CORRELATION MATRIX\n",
      "------------------ START ITERATING THROUGH FEATURE SET\n",
      "------------------ ITERATION STEP 1\n",
      "n_requests_1 selected with MRMR-Score: 0.0\n",
      "------------------ ITERATION STEP 2\n",
      "diff_n_requests_2 selected with MRMR-Score: 92.17599347330358\n",
      "------------------ ITERATION STEP 3\n",
      "diff_n_requests_1 selected with MRMR-Score: 168.95605860281208\n",
      "------------------ ITERATION STEP 4\n",
      "diff_n_requests_3 selected with MRMR-Score: 175.57501022755906\n",
      "------------------ ITERATION STEP 5\n",
      "n_requests_3 selected with MRMR-Score: 47.69890546075745\n",
      "------------------ ITERATION STEP 6\n",
      "diff_avg_vjnbe_requests_3 selected with MRMR-Score: 57.001898906841234\n",
      "------------------ ITERATION STEP 7\n",
      "n_requests_2 selected with MRMR-Score: 18.423702387718812\n",
      "------------------ ITERATION STEP 8\n",
      "diff_avg_vjnbe_requests_2 selected with MRMR-Score: 18.485858390908493\n",
      "------------------ ITERATION STEP 9\n",
      "other_hsntsn_requests_3 selected with MRMR-Score: 5.1888898316179235\n",
      "------------------ ITERATION STEP 10\n",
      "other_hsntsn_requests_2 selected with MRMR-Score: 0.0\n",
      "------------------ ITERATION STEP 11\n",
      "other_hsntsn_requests_1 selected with MRMR-Score: 0.0\n",
      "------------------ ITERATION STEP 12\n",
      "diff_avg_vjnbe_requests_1 selected with MRMR-Score: 0.0\n",
      "------------------ END ITERATING THROUGH FEATURE SET\n",
      "..1: Small preprocessing\n",
      "Memory usage decreased to  0.09 Mb (84.7% reduction)\n",
      "Memory usage decreased to  0.18 Mb (76.2% reduction)\n",
      "..2: Start CV-HP-Tuning\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.104695\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.104679\n",
      "..3: Finished CV-HP-Tuning\n",
      "Best score reached: 0.9109205260148657 with params: {'colsample_bytree': 0.6192404735242193, 'min_child_samples': 210, 'min_child_weight': 0.01, 'num_leaves': 6, 'reg_alpha': 0, 'reg_lambda': 0, 'subsample': 0.4185032881682477} \n",
      "..4: Save best model\n",
      "Memory usage decreased to  0.17 Mb (75.0% reduction)\n",
      "Memory usage decreased to  0.17 Mb (75.0% reduction)\n",
      "..1: Small preprocessing\n",
      "Memory usage decreased to  0.09 Mb (0.0% reduction)\n",
      "Memory usage decreased to  0.18 Mb (0.0% reduction)\n",
      "..2: Start CV-HP-Tuning\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[100]\tvalid_0's binary_logloss: 0.137741\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.104679\n",
      "..3: Finished CV-HP-Tuning\n",
      "Best score reached: 0.9108061749571185 with params: {'colsample_bytree': 0.8565249561837849, 'min_child_samples': 440, 'min_child_weight': 1e-05, 'num_leaves': 44, 'reg_alpha': 5, 'reg_lambda': 100, 'subsample': 0.7686013901257656} \n",
      "..4: Save best model\n",
      "Memory usage decreased to  0.17 Mb (75.0% reduction)\n",
      "Memory usage decreased to  0.17 Mb (75.0% reduction)\n",
      "..1: Small preprocessing\n",
      "Memory usage decreased to  0.16 Mb (81.7% reduction)\n",
      "Memory usage decreased to  0.25 Mb (76.8% reduction)\n",
      "..2: Start CV-HP-Tuning\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[100]\tvalid_0's binary_logloss: 0.119862\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.104679\n",
      "..3: Finished CV-HP-Tuning\n",
      "Best score reached: 0.9233847913093195 with params: {'colsample_bytree': 0.941895985398026, 'min_child_samples': 453, 'min_child_weight': 10.0, 'num_leaves': 42, 'reg_alpha': 10, 'reg_lambda': 10, 'subsample': 0.8182441374592413} \n",
      "..4: Save best model\n",
      "Memory usage decreased to  0.25 Mb (75.0% reduction)\n",
      "Memory usage decreased to  0.25 Mb (75.0% reduction)\n",
      "..1: Small preprocessing\n",
      "Memory usage decreased to  0.16 Mb (0.0% reduction)\n",
      "Memory usage decreased to  0.25 Mb (0.0% reduction)\n",
      "..2: Start CV-HP-Tuning\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[100]\tvalid_0's binary_logloss: 0.120061\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.104679\n",
      "..3: Finished CV-HP-Tuning\n",
      "Best score reached: 0.923956546598056 with params: {'colsample_bytree': 0.8345033928052394, 'min_child_samples': 381, 'min_child_weight': 1e-05, 'num_leaves': 49, 'reg_alpha': 5, 'reg_lambda': 1, 'subsample': 0.8203972155309016} \n",
      "..4: Save best model\n",
      "Memory usage decreased to  0.25 Mb (75.0% reduction)\n",
      "Memory usage decreased to  0.25 Mb (75.0% reduction)\n",
      "------------------ COMPUTE CORRELATION MATRIX\n",
      "------------------ START ITERATING THROUGH FEATURE SET\n",
      "------------------ ITERATION STEP 1\n",
      "n_requests_1 selected with MRMR-Score: 2.6\n",
      "------------------ ITERATION STEP 2\n",
      "diff_avg_vjnbe_requests_3 selected with MRMR-Score: 367.88637625360616\n",
      "------------------ ITERATION STEP 3\n",
      "diff_n_requests_3 selected with MRMR-Score: 462.1443533451757\n",
      "------------------ ITERATION STEP 4\n",
      "diff_n_requests_1 selected with MRMR-Score: 418.73166486943853\n",
      "------------------ ITERATION STEP 5\n",
      "diff_n_requests_2 selected with MRMR-Score: 683.816762107335\n",
      "------------------ ITERATION STEP 6\n",
      "other_hsntsn_requests_3 selected with MRMR-Score: 312.2726188985778\n",
      "------------------ ITERATION STEP 7\n",
      "n_requests_3 selected with MRMR-Score: 369.1414008477213\n",
      "------------------ ITERATION STEP 8\n",
      "diff_avg_vjnbe_requests_2 selected with MRMR-Score: 318.75907325998486\n",
      "------------------ ITERATION STEP 9\n",
      "other_hsntsn_requests_2 selected with MRMR-Score: 318.93062203064096\n",
      "------------------ ITERATION STEP 10\n",
      "n_requests_2 selected with MRMR-Score: 429.23376622125244\n",
      "------------------ ITERATION STEP 11\n",
      "diff_avg_vjnbe_requests_1 selected with MRMR-Score: 538.8170413596334\n",
      "------------------ ITERATION STEP 12\n",
      "other_hsntsn_requests_1 selected with MRMR-Score: 573.8383043868912\n",
      "------------------ END ITERATING THROUGH FEATURE SET\n",
      "..1: Small preprocessing\n",
      "Memory usage decreased to  0.42 Mb (84.7% reduction)\n",
      "Memory usage decreased to  0.18 Mb (76.2% reduction)\n",
      "..2: Start CV-HP-Tuning\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.056501\n",
      "..3: Finished CV-HP-Tuning\n",
      "Best score reached: 0.9796110301428723 with params: {'colsample_bytree': 0.7469351576744102, 'min_child_samples': 319, 'min_child_weight': 0.1, 'num_leaves': 6, 'reg_alpha': 1, 'reg_lambda': 10, 'subsample': 0.8147160409757632} \n",
      "..4: Save best model\n",
      "Memory usage decreased to  0.17 Mb (75.0% reduction)\n",
      "Memory usage decreased to  0.17 Mb (75.0% reduction)\n",
      "..1: Small preprocessing\n",
      "Memory usage decreased to  0.42 Mb (0.0% reduction)\n",
      "Memory usage decreased to  0.18 Mb (0.0% reduction)\n",
      "..2: Start CV-HP-Tuning\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's binary_logloss: 0.0564727\n",
      "..3: Finished CV-HP-Tuning\n",
      "Best score reached: 0.9795615411170638 with params: {'colsample_bytree': 0.6612718434434947, 'min_child_samples': 290, 'min_child_weight': 0.01, 'num_leaves': 23, 'reg_alpha': 5, 'reg_lambda': 0, 'subsample': 0.9340928131920943} \n",
      "..4: Save best model\n",
      "Memory usage decreased to  0.17 Mb (75.0% reduction)\n",
      "Memory usage decreased to  0.17 Mb (75.0% reduction)\n",
      "..1: Small preprocessing\n",
      "Memory usage decreased to  0.73 Mb (81.7% reduction)\n",
      "Memory usage decreased to  0.25 Mb (76.8% reduction)\n",
      "..2: Start CV-HP-Tuning\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's binary_logloss: 0.0520157\n",
      "..3: Finished CV-HP-Tuning\n",
      "Best score reached: 0.9816895086145289 with params: {'colsample_bytree': 0.6204504771560414, 'min_child_samples': 477, 'min_child_weight': 0.01, 'num_leaves': 24, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.5351238842061709} \n",
      "..4: Save best model\n",
      "Memory usage decreased to  0.25 Mb (75.0% reduction)\n",
      "Memory usage decreased to  0.25 Mb (75.0% reduction)\n",
      "..1: Small preprocessing\n",
      "Memory usage decreased to  0.73 Mb (0.0% reduction)\n",
      "Memory usage decreased to  0.25 Mb (0.0% reduction)\n",
      "..2: Start CV-HP-Tuning\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's binary_logloss: 0.0516405\n",
      "..3: Finished CV-HP-Tuning\n",
      "Best score reached: 0.981664775122043 with params: {'colsample_bytree': 0.8611136052619532, 'min_child_samples': 158, 'min_child_weight': 0.1, 'num_leaves': 23, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.6968101584818931} \n",
      "..4: Save best model\n",
      "Memory usage decreased to  0.25 Mb (75.0% reduction)\n",
      "Memory usage decreased to  0.25 Mb (75.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "results_df = gbt_modelling.fit_and_eval_lgbm_candidates(\n",
    "    hp_struct_dict=hp_struct_dict,\n",
    "    hp_fix_dict=hp_fix_dict,\n",
    "    hp_tune_dict=hp_tune_dict,\n",
    "    hp_eval_dict=hp_eval_dict,\n",
    "    rscv_params=rscv_params,\n",
    "    path_to_folder=SCRIPT_DIR,\n",
    "    feature_set_from_last_fits=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            sampling  dr_method  \\\n",
       "lgbm_fit_gbt_down2_best_quot_a0.6_gNone   down2: 0.5  best_quot   \n",
       "lgbm_fit_gbt_down2_best_quot_aNone_gNone  down2: 0.5  best_quot   \n",
       "lgbm_fit_gbt_down1_best_quot_a0.6_gNone   down1: 0.1  best_quot   \n",
       "lgbm_fit_gbt_down1_best_quot_aNone_gNone  down1: 0.1  best_quot   \n",
       "lgbm_fit_gbt_down1_no_quot_a0.6_gNone     down1: 0.1    no_quot   \n",
       "lgbm_fit_gbt_down1_no_quot_aNone_gNone    down1: 0.1    no_quot   \n",
       "lgbm_fit_gbt_down2_no_quot_aNone_gNone    down2: 0.5    no_quot   \n",
       "lgbm_fit_gbt_down2_no_quot_a0.6_gNone     down2: 0.5    no_quot   \n",
       "\n",
       "                                                                          features_after_dr  \\\n",
       "lgbm_fit_gbt_down2_best_quot_a0.6_gNone   [n_requests_1, diff_avg_vjnbe_requests_3, diff...   \n",
       "lgbm_fit_gbt_down2_best_quot_aNone_gNone  [n_requests_1, diff_avg_vjnbe_requests_3, diff...   \n",
       "lgbm_fit_gbt_down1_best_quot_a0.6_gNone   [n_requests_1, diff_n_requests_2, diff_avg_vjn...   \n",
       "lgbm_fit_gbt_down1_best_quot_aNone_gNone  [n_requests_1, diff_n_requests_2, diff_avg_vjn...   \n",
       "lgbm_fit_gbt_down1_no_quot_a0.6_gNone     [n_accident, sum_accident_cost, vehicle_age, d...   \n",
       "lgbm_fit_gbt_down1_no_quot_aNone_gNone    [n_accident, sum_accident_cost, vehicle_age, d...   \n",
       "lgbm_fit_gbt_down2_no_quot_aNone_gNone    [n_accident, sum_accident_cost, vehicle_age, d...   \n",
       "lgbm_fit_gbt_down2_no_quot_a0.6_gNone     [n_accident, sum_accident_cost, vehicle_age, d...   \n",
       "\n",
       "                                                                    loss  \\\n",
       "lgbm_fit_gbt_down2_best_quot_a0.6_gNone    {'alpha': 0.6, 'gamma': None}   \n",
       "lgbm_fit_gbt_down2_best_quot_aNone_gNone  {'alpha': None, 'gamma': None}   \n",
       "lgbm_fit_gbt_down1_best_quot_a0.6_gNone    {'alpha': 0.6, 'gamma': None}   \n",
       "lgbm_fit_gbt_down1_best_quot_aNone_gNone  {'alpha': None, 'gamma': None}   \n",
       "lgbm_fit_gbt_down1_no_quot_a0.6_gNone      {'alpha': 0.6, 'gamma': None}   \n",
       "lgbm_fit_gbt_down1_no_quot_aNone_gNone    {'alpha': None, 'gamma': None}   \n",
       "lgbm_fit_gbt_down2_no_quot_aNone_gNone    {'alpha': None, 'gamma': None}   \n",
       "lgbm_fit_gbt_down2_no_quot_a0.6_gNone      {'alpha': 0.6, 'gamma': None}   \n",
       "\n",
       "                                                                                      model  \\\n",
       "lgbm_fit_gbt_down2_best_quot_a0.6_gNone   LGBMClassifier(colsample_bytree=0.861113605261...   \n",
       "lgbm_fit_gbt_down2_best_quot_aNone_gNone  LGBMClassifier(colsample_bytree=0.620450477156...   \n",
       "lgbm_fit_gbt_down1_best_quot_a0.6_gNone   LGBMClassifier(colsample_bytree=0.834503392805...   \n",
       "lgbm_fit_gbt_down1_best_quot_aNone_gNone  LGBMClassifier(colsample_bytree=0.941895985398...   \n",
       "lgbm_fit_gbt_down1_no_quot_a0.6_gNone     LGBMClassifier(colsample_bytree=0.856524956183...   \n",
       "lgbm_fit_gbt_down1_no_quot_aNone_gNone    LGBMClassifier(colsample_bytree=0.619240473524...   \n",
       "lgbm_fit_gbt_down2_no_quot_aNone_gNone    LGBMClassifier(colsample_bytree=0.746935157674...   \n",
       "lgbm_fit_gbt_down2_no_quot_a0.6_gNone     LGBMClassifier(colsample_bytree=0.661271843443...   \n",
       "\n",
       "                                          Accuracy_OOS  Precision_OOS  \\\n",
       "lgbm_fit_gbt_down2_best_quot_a0.6_gNone         0.9903       0.562500   \n",
       "lgbm_fit_gbt_down2_best_quot_aNone_gNone        0.9906       0.584906   \n",
       "lgbm_fit_gbt_down1_best_quot_a0.6_gNone         0.9701       0.177632   \n",
       "lgbm_fit_gbt_down1_best_quot_aNone_gNone        0.9721       0.185714   \n",
       "lgbm_fit_gbt_down1_no_quot_a0.6_gNone           0.9719       0.129167   \n",
       "lgbm_fit_gbt_down1_no_quot_aNone_gNone          0.9795       0.140845   \n",
       "lgbm_fit_gbt_down2_no_quot_aNone_gNone          0.9897       0.000000   \n",
       "lgbm_fit_gbt_down2_no_quot_a0.6_gNone           0.9896       0.000000   \n",
       "\n",
       "                                          Recall_OOS  F1_Score_OOS  AUROC_OOS  \\\n",
       "lgbm_fit_gbt_down2_best_quot_a0.6_gNone     0.262136      0.357616   0.895334   \n",
       "lgbm_fit_gbt_down2_best_quot_aNone_gNone    0.300971      0.397436   0.897244   \n",
       "lgbm_fit_gbt_down1_best_quot_a0.6_gNone     0.524272      0.265356   0.902293   \n",
       "lgbm_fit_gbt_down1_best_quot_aNone_gNone    0.504854      0.271540   0.899934   \n",
       "lgbm_fit_gbt_down1_no_quot_a0.6_gNone       0.300971      0.180758   0.859534   \n",
       "lgbm_fit_gbt_down1_no_quot_aNone_gNone      0.194175      0.163265   0.854789   \n",
       "lgbm_fit_gbt_down2_no_quot_aNone_gNone      0.000000      0.000000   0.855990   \n",
       "lgbm_fit_gbt_down2_no_quot_a0.6_gNone       0.000000      0.000000   0.853470   \n",
       "\n",
       "                                          AUPRC_OOS  Accuracy_OOP  \\\n",
       "lgbm_fit_gbt_down2_best_quot_a0.6_gNone    0.323259        0.9883   \n",
       "lgbm_fit_gbt_down2_best_quot_aNone_gNone   0.340650        0.9882   \n",
       "lgbm_fit_gbt_down1_best_quot_a0.6_gNone    0.314105        0.9666   \n",
       "lgbm_fit_gbt_down1_best_quot_aNone_gNone   0.297274        0.9679   \n",
       "lgbm_fit_gbt_down1_no_quot_a0.6_gNone      0.092998        0.9658   \n",
       "lgbm_fit_gbt_down1_no_quot_aNone_gNone     0.086480        0.9766   \n",
       "lgbm_fit_gbt_down2_no_quot_aNone_gNone     0.087939        0.9883   \n",
       "lgbm_fit_gbt_down2_no_quot_a0.6_gNone      0.091878        0.9883   \n",
       "\n",
       "                                          Precision_OOP  Recall_OOP  \\\n",
       "lgbm_fit_gbt_down2_best_quot_a0.6_gNone        0.500000    0.153846   \n",
       "lgbm_fit_gbt_down2_best_quot_aNone_gNone       0.486486    0.153846   \n",
       "lgbm_fit_gbt_down1_best_quot_a0.6_gNone        0.129693    0.324786   \n",
       "lgbm_fit_gbt_down1_best_quot_aNone_gNone       0.127737    0.299145   \n",
       "lgbm_fit_gbt_down1_no_quot_a0.6_gNone          0.081784    0.188034   \n",
       "lgbm_fit_gbt_down1_no_quot_aNone_gNone         0.102041    0.128205   \n",
       "lgbm_fit_gbt_down2_no_quot_aNone_gNone         0.000000    0.000000   \n",
       "lgbm_fit_gbt_down2_no_quot_a0.6_gNone          0.000000    0.000000   \n",
       "\n",
       "                                          F1_Score_OOP  AUROC_OOP  AUPRC_OOP  \\\n",
       "lgbm_fit_gbt_down2_best_quot_a0.6_gNone       0.235294   0.856748   0.197048   \n",
       "lgbm_fit_gbt_down2_best_quot_aNone_gNone      0.233766   0.856956   0.203304   \n",
       "lgbm_fit_gbt_down1_best_quot_a0.6_gNone       0.185366   0.859481   0.178492   \n",
       "lgbm_fit_gbt_down1_best_quot_aNone_gNone      0.179028   0.859508   0.166410   \n",
       "lgbm_fit_gbt_down1_no_quot_a0.6_gNone         0.113990   0.835907   0.063473   \n",
       "lgbm_fit_gbt_down1_no_quot_aNone_gNone        0.113636   0.837156   0.065584   \n",
       "lgbm_fit_gbt_down2_no_quot_aNone_gNone        0.000000   0.837549   0.065555   \n",
       "lgbm_fit_gbt_down2_no_quot_a0.6_gNone         0.000000   0.832324   0.061750   \n",
       "\n",
       "                                                                                       path  \n",
       "lgbm_fit_gbt_down2_best_quot_a0.6_gNone   /Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...  \n",
       "lgbm_fit_gbt_down2_best_quot_aNone_gNone  /Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...  \n",
       "lgbm_fit_gbt_down1_best_quot_a0.6_gNone   /Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...  \n",
       "lgbm_fit_gbt_down1_best_quot_aNone_gNone  /Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...  \n",
       "lgbm_fit_gbt_down1_no_quot_a0.6_gNone     /Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...  \n",
       "lgbm_fit_gbt_down1_no_quot_aNone_gNone    /Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...  \n",
       "lgbm_fit_gbt_down2_no_quot_aNone_gNone    /Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...  \n",
       "lgbm_fit_gbt_down2_no_quot_a0.6_gNone     /Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sampling</th>\n      <th>dr_method</th>\n      <th>features_after_dr</th>\n      <th>loss</th>\n      <th>model</th>\n      <th>Accuracy_OOS</th>\n      <th>Precision_OOS</th>\n      <th>Recall_OOS</th>\n      <th>F1_Score_OOS</th>\n      <th>AUROC_OOS</th>\n      <th>AUPRC_OOS</th>\n      <th>Accuracy_OOP</th>\n      <th>Precision_OOP</th>\n      <th>Recall_OOP</th>\n      <th>F1_Score_OOP</th>\n      <th>AUROC_OOP</th>\n      <th>AUPRC_OOP</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lgbm_fit_gbt_down2_best_quot_a0.6_gNone</th>\n      <td>down2: 0.5</td>\n      <td>best_quot</td>\n      <td>[n_requests_1, diff_avg_vjnbe_requests_3, diff...</td>\n      <td>{'alpha': 0.6, 'gamma': None}</td>\n      <td>LGBMClassifier(colsample_bytree=0.861113605261...</td>\n      <td>0.9903</td>\n      <td>0.562500</td>\n      <td>0.262136</td>\n      <td>0.357616</td>\n      <td>0.895334</td>\n      <td>0.323259</td>\n      <td>0.9883</td>\n      <td>0.500000</td>\n      <td>0.153846</td>\n      <td>0.235294</td>\n      <td>0.856748</td>\n      <td>0.197048</td>\n      <td>/Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...</td>\n    </tr>\n    <tr>\n      <th>lgbm_fit_gbt_down2_best_quot_aNone_gNone</th>\n      <td>down2: 0.5</td>\n      <td>best_quot</td>\n      <td>[n_requests_1, diff_avg_vjnbe_requests_3, diff...</td>\n      <td>{'alpha': None, 'gamma': None}</td>\n      <td>LGBMClassifier(colsample_bytree=0.620450477156...</td>\n      <td>0.9906</td>\n      <td>0.584906</td>\n      <td>0.300971</td>\n      <td>0.397436</td>\n      <td>0.897244</td>\n      <td>0.340650</td>\n      <td>0.9882</td>\n      <td>0.486486</td>\n      <td>0.153846</td>\n      <td>0.233766</td>\n      <td>0.856956</td>\n      <td>0.203304</td>\n      <td>/Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...</td>\n    </tr>\n    <tr>\n      <th>lgbm_fit_gbt_down1_best_quot_a0.6_gNone</th>\n      <td>down1: 0.1</td>\n      <td>best_quot</td>\n      <td>[n_requests_1, diff_n_requests_2, diff_avg_vjn...</td>\n      <td>{'alpha': 0.6, 'gamma': None}</td>\n      <td>LGBMClassifier(colsample_bytree=0.834503392805...</td>\n      <td>0.9701</td>\n      <td>0.177632</td>\n      <td>0.524272</td>\n      <td>0.265356</td>\n      <td>0.902293</td>\n      <td>0.314105</td>\n      <td>0.9666</td>\n      <td>0.129693</td>\n      <td>0.324786</td>\n      <td>0.185366</td>\n      <td>0.859481</td>\n      <td>0.178492</td>\n      <td>/Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...</td>\n    </tr>\n    <tr>\n      <th>lgbm_fit_gbt_down1_best_quot_aNone_gNone</th>\n      <td>down1: 0.1</td>\n      <td>best_quot</td>\n      <td>[n_requests_1, diff_n_requests_2, diff_avg_vjn...</td>\n      <td>{'alpha': None, 'gamma': None}</td>\n      <td>LGBMClassifier(colsample_bytree=0.941895985398...</td>\n      <td>0.9721</td>\n      <td>0.185714</td>\n      <td>0.504854</td>\n      <td>0.271540</td>\n      <td>0.899934</td>\n      <td>0.297274</td>\n      <td>0.9679</td>\n      <td>0.127737</td>\n      <td>0.299145</td>\n      <td>0.179028</td>\n      <td>0.859508</td>\n      <td>0.166410</td>\n      <td>/Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...</td>\n    </tr>\n    <tr>\n      <th>lgbm_fit_gbt_down1_no_quot_a0.6_gNone</th>\n      <td>down1: 0.1</td>\n      <td>no_quot</td>\n      <td>[n_accident, sum_accident_cost, vehicle_age, d...</td>\n      <td>{'alpha': 0.6, 'gamma': None}</td>\n      <td>LGBMClassifier(colsample_bytree=0.856524956183...</td>\n      <td>0.9719</td>\n      <td>0.129167</td>\n      <td>0.300971</td>\n      <td>0.180758</td>\n      <td>0.859534</td>\n      <td>0.092998</td>\n      <td>0.9658</td>\n      <td>0.081784</td>\n      <td>0.188034</td>\n      <td>0.113990</td>\n      <td>0.835907</td>\n      <td>0.063473</td>\n      <td>/Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...</td>\n    </tr>\n    <tr>\n      <th>lgbm_fit_gbt_down1_no_quot_aNone_gNone</th>\n      <td>down1: 0.1</td>\n      <td>no_quot</td>\n      <td>[n_accident, sum_accident_cost, vehicle_age, d...</td>\n      <td>{'alpha': None, 'gamma': None}</td>\n      <td>LGBMClassifier(colsample_bytree=0.619240473524...</td>\n      <td>0.9795</td>\n      <td>0.140845</td>\n      <td>0.194175</td>\n      <td>0.163265</td>\n      <td>0.854789</td>\n      <td>0.086480</td>\n      <td>0.9766</td>\n      <td>0.102041</td>\n      <td>0.128205</td>\n      <td>0.113636</td>\n      <td>0.837156</td>\n      <td>0.065584</td>\n      <td>/Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...</td>\n    </tr>\n    <tr>\n      <th>lgbm_fit_gbt_down2_no_quot_aNone_gNone</th>\n      <td>down2: 0.5</td>\n      <td>no_quot</td>\n      <td>[n_accident, sum_accident_cost, vehicle_age, d...</td>\n      <td>{'alpha': None, 'gamma': None}</td>\n      <td>LGBMClassifier(colsample_bytree=0.746935157674...</td>\n      <td>0.9897</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.855990</td>\n      <td>0.087939</td>\n      <td>0.9883</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.837549</td>\n      <td>0.065555</td>\n      <td>/Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...</td>\n    </tr>\n    <tr>\n      <th>lgbm_fit_gbt_down2_no_quot_a0.6_gNone</th>\n      <td>down2: 0.5</td>\n      <td>no_quot</td>\n      <td>[n_accident, sum_accident_cost, vehicle_age, d...</td>\n      <td>{'alpha': 0.6, 'gamma': None}</td>\n      <td>LGBMClassifier(colsample_bytree=0.661271843443...</td>\n      <td>0.9896</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.853470</td>\n      <td>0.091878</td>\n      <td>0.9883</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.832324</td>\n      <td>0.061750</td>\n      <td>/Users/abdumaa/Desktop/Uni_Abdu/Master/Mastera...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}